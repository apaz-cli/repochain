{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = \".api_key\"\n",
    "repo_url = \"https://git.savannah.gnu.org/git/nano.git\"\n",
    "repo_path = \"/tmp/nano\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read OAI api key\n",
    "import os\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    with open(key_path, \"r\") as f:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = str(f.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo\n",
    "from git import Repo\n",
    "from os.path import isdir\n",
    "def load_repo(repo_path):\n",
    "    if not isdir(repo_path):\n",
    "        return Repo.clone_from(repo_url, to_path=repo_path)\n",
    "    else:\n",
    "        return Repo(repo_path)\n",
    "repo = load_repo(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import azure.core python package.\n"
     ]
    }
   ],
   "source": [
    "# Create langchain loader\n",
    "from langchain.document_loaders import GitLoader\n",
    "loader = GitLoader(repo_path=repo_path, branch=repo.head.reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 documents.\n"
     ]
    }
   ],
   "source": [
    "# Load/filter documents\n",
    "extensions = ['.c', '.h', '.cpp', '.py', '.sh', '.java', '.js', '.mjs', '.html', '.css', '.php', '.pl', '.pm', '.rb', '.lua', '.rs', '.go' '.md']\n",
    "documents = [f for f in loader.load() if f.metadata['file_type'] == '.c']\n",
    "print(f\"Loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 829 texts.\n"
     ]
    }
   ],
   "source": [
    "# Split documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "texts = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100).split_documents(documents)\n",
    "print(f\"Split into {len(texts)} texts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 829 embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Embed documents\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embed_model = OpenAIEmbeddings()\n",
    "embeddings = None\n",
    "import pickle\n",
    "if os.path.exists(\"embeddings.pkl\"):\n",
    "    with open(\"embeddings.pkl\", \"rb\") as f:\n",
    "        embeddings = pickle.load(f)\n",
    "else:\n",
    "    embeddings = embed_model.embed_documents([t.page_content for t in texts])\n",
    "    with open(\"embeddings.pkl\", \"wb\") as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "        print(\"Saved embeddings.\")\n",
    "print(f\"Loaded {len(embeddings)} embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector db\n",
    "from langchain.vectorstores import Annoy\n",
    "docsearch = Annoy.from_embeddings(\n",
    "                [(t.page_content, e) for t, e in zip(texts, embeddings)],\n",
    "                embed_model,\n",
    "                metadatas=[t.metadata for t in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"Use the following pieces of code to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QA chain (document vector DB -> LLM)\n",
    "from langchain.chains import RetrievalQA\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                    chain_type=\"stuff\",\n",
    "                                    retriever=docsearch.as_retriever(),\n",
    "                                    chain_type_kwargs=chain_type_kwargs,\n",
    "                                    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`run` not supported when there is not exactly one output key. Got ['result', 'source_documents'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Execute the langchain\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mrun(prompt)\n\u001b[1;32m      4\u001b[0m text_response \u001b[39m=\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m docs_used \u001b[39m=\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/git/repochain/lib/python3.11/site-packages/langchain/chains/base.py:228\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run the chain as text in, text out or multiple variables, text out.\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    229\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` not supported when there is not exactly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mone output key. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     )\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs:\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: `run` not supported when there is not exactly one output key. Got ['result', 'source_documents']."
     ]
    }
   ],
   "source": [
    "# Execute the langchain\n",
    "result = chain.run(prompt)\n",
    "\n",
    "text_response = result[\"result\"]\n",
    "docs_used = result[\"source_documents\"]\n",
    "\n",
    "print(f\"Response:\\n{text_response.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
